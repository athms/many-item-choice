{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# custom imports\n",
    "from utils.plotting import despine, cm2inch\n",
    "from utils.general import make_sure_path_exists\n",
    "from utils.descriptives import compute_gaze_influence_score, compute_p_last_gaze_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptives & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/summary_files/9_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-48ebc0902a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msetsize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msetsizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdf_setsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'summary_files/{}_data.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mdf_setsize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'setsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_setsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/GLAM/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/GLAM/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/GLAM/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/GLAM/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/GLAM/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/summary_files/9_data.csv'"
     ]
    }
   ],
   "source": [
    "# directory of data\n",
    "data_dir = '../data/'\n",
    "figure_dir = '../figures/'\n",
    "\n",
    "# make sure output dir exists\n",
    "make_sure_path_exists(figure_dir)\n",
    "\n",
    "# choice set sizes\n",
    "setsizes = np.array([9, 16, 25, 36])\n",
    "colors = ['darkturquoise', 'orange', 'mediumseagreen', 'lightcoral']\n",
    "n_trials_per_setsize = 50\n",
    "\n",
    "# read in response data\n",
    "data =[]\n",
    "for setsize in setsizes:\n",
    "    df_setsize = pd.read_csv(data_dir+'summary_files/{}_data.csv'.format(setsize))\n",
    "    df_setsize['setsize'] = setsize\n",
    "    data.append(df_setsize)\n",
    "data = pd.concat(data, sort=True)\n",
    "\n",
    "# add RT in seconds\n",
    "data['rt_s'] = data['rt'].values / 1000.\n",
    "    \n",
    "# read out subject IDs\n",
    "subjects = np.unique(data.subject)\n",
    "n_subjects = subjects.size\n",
    "    \n",
    "# read in gaze data\n",
    "gaze_data = []\n",
    "for subject in subjects:\n",
    "    for c in setsizes:\n",
    "        tmp_data = pd.read_csv(data_dir+'subject_files/{}_{}_fixations.csv'.format(subject, c))\n",
    "        tmp_data = tmp_data[[c for c in tmp_data.columns if not 'Unnamed:' in c]]\n",
    "        gaze_data.append(tmp_data)\n",
    "gaze_data = pd.concat(gaze_data, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_associations_figure_4F(data, gaze_data, setsizes=np.array([9,16,25,36]), verbose=False):\n",
    "    \"\"\"Compute Spearman rank correlations for associations  \n",
    "    shown in Fig. 4 F of the manuscript. \n",
    "    \n",
    "    Args:\n",
    "        data (dataframe): choice data   \n",
    "        gaze_data (dataframe): gaze data\n",
    "        setsizes (array of int): choice set size conditions\n",
    "        verbose (bool): whether to print results of each\n",
    "            association test\n",
    "                \n",
    "    Returns:\n",
    "        matrix with correlation coefficients and p-values:\n",
    "        (var A x var B x (correlation coefficient, p-value))\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Seen items count vs set-size\n",
    "    data['frac_items_seen'] = (data['seen_items_count'] / data['setsize']).values.astype(np.float)\n",
    "    sub_frac_items_seen = np.concatenate(\n",
    "        [data.groupby(['setsize', 'subject']).frac_items_seen.mean()[s][:,None] for s in setsizes],\n",
    "        axis=1)\n",
    "    \n",
    "    # 2. Response time vs set-size\n",
    "    sub_rt_means = np.concatenate(\n",
    "        [data.groupby(['setsize', 'subject']).rt_s.mean()[s][:,None] for s in setsizes],\n",
    "        axis=1)\n",
    "    \n",
    "    # 3. P(choose best seen item )\n",
    "    sub_best_seen_chosen_means = np.concatenate(\n",
    "        [data.groupby(['setsize','subject']).best_seen_chosen.mean()[s][:,None] for s in setsizes],\n",
    "        axis=1)\n",
    "    \n",
    "    # 4. P(last gaze to choice)\n",
    "    (sub_p_last_fix_choice_means,\n",
    "     p_last_fix_choice_means,\n",
    "     p_last_fix_choice_sems) = compute_p_last_gaze_choice(data, gaze_data)\n",
    "    \n",
    "    # 5. Gaze Influence on choice probability\n",
    "    sub_gaze_influence_scores = []\n",
    "    for setsize in setsizes:\n",
    "        sub_gaze_influence_scores.append(compute_gaze_influence_score(data[data['setsize']==setsize].copy()))\n",
    "    sub_gaze_influence_scores = np.concatenate([s[:,None] for s in sub_gaze_influence_scores],\n",
    "                                               axis=1)\n",
    "    \n",
    "    # Make df (average over setsizes)\n",
    "    assoc_df = pd.DataFrame({'subject': subjects,\n",
    "                             'frac_items_seen': sub_frac_items_seen.mean(axis=1),\n",
    "                             'RT': sub_rt_means.mean(axis=1),\n",
    "                             'best_chosen': sub_best_seen_chosen_means.mean(axis=1),\n",
    "                             'last_gaze_to_choice': sub_p_last_fix_choice_means.mean(axis=1),\n",
    "                             'gaze_influence': sub_gaze_influence_scores.mean(axis=1)})\n",
    "    \n",
    "    # Define combinations\n",
    "    xs = ['best_chosen', 'best_chosen', 'best_chosen', 'best_chosen', 'best_chosen',\n",
    "          'frac_items_seen', 'frac_items_seen', 'frac_items_seen', 'frac_items_seen',\n",
    "          'RT', 'RT', 'RT',\n",
    "          'last_gaze_to_choice', 'last_gaze_to_choice',\n",
    "          'gaze_influence']\n",
    "    ys = ['best_chosen', 'frac_items_seen', 'RT', 'last_gaze_to_choice', 'gaze_influence',\n",
    "          'frac_items_seen', 'RT', 'last_gaze_to_choice', 'gaze_influence',\n",
    "          'RT', 'last_gaze_to_choice', 'gaze_influence',\n",
    "          'last_gaze_to_choice', 'gaze_influence',\n",
    "          'gaze_influence']\n",
    "    pos = [(0,0), (1,0), (2,0), (3,0), (4,0),\n",
    "           (1,1), (2,1), (3,1), (4,1),\n",
    "           (2,2), (3,2), (4,2),\n",
    "           (3,3), (4,3),\n",
    "           (4,4)]\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nCorrelation coefficients:')\n",
    "    \n",
    "    # Compute correlations\n",
    "    association_mat = np.zeros((5,5,2)) * np.nan\n",
    "    for x, y, (xi, yi) in zip(xs, ys, pos):\n",
    "        if verbose:\n",
    "            print('\\n{} ~ {}'.format(x,y))\n",
    "        r, p = spearmanr(assoc_df[x], assoc_df[y])\n",
    "        if verbose:\n",
    "            print('Spearman r = {}, p = {}'.format(r, p))\n",
    "        association_mat[xi, yi] = r, p\n",
    "    \n",
    "    return association_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4-figure supplement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scatter(x, y, ax, color, label=None):\n",
    "    ax.scatter(x, y, marker='o', color='none', edgecolor=color, \n",
    "               linewidth=0.75, alpha=1, s=20)\n",
    "    ax.scatter(x, y, marker='o', color=color, alpha=0.2,\n",
    "               linewidth=0, s=20, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _annotation(i,j,corr_mat):\n",
    "    rval, pval = corr_mat[i,j,:]\n",
    "    if pval < 0.0001:\n",
    "        p_string = r'$P < 0.0001$'\n",
    "    else:\n",
    "        p_string = r'$P = {}$'.format(np.round(pval, 4))\n",
    "    annotation = (r'$\\rho(48)$'+r'$ = {:.2f}$, '.format(rval)) + p_string\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_4_figure_supplement_1(data, gaze_data, colors=['darkturquoise', 'orange', 'mediumseagreen', 'lightcoral'], \n",
    "              fontsize=8, dpi=300):\n",
    "    \"\"\"Create SI Figure 4 of the manuscript.\n",
    "    \n",
    "    Args:\n",
    "        data (dataframe): choice data   \n",
    "        gaze_data (dataframe): gaze data\n",
    "        colors (array of strings): colors to use for set sizes\n",
    "        fontsize (int): fontisze for labeling \n",
    "        dpi (int): dpi of figure\n",
    "                \n",
    "    Returns:\n",
    "        matplotlib figure / axis\n",
    "    \"\"\"\n",
    "    \n",
    "    # COMPUTE SUBJECT MEANS:\n",
    "    n_subjects = data.subject.unique().size\n",
    "    \n",
    "    # 1. Seen items count vs set-size\n",
    "    data['frac_items_seen'] = (data['seen_items_count'] / data['setsize']).values.astype(np.float)\n",
    "    sub_frac_items_seen = np.concatenate(\n",
    "        [data.groupby(['setsize', 'subject']).frac_items_seen.mean()[s][:,None]\n",
    "         for s in setsizes], axis=1)\n",
    "    \n",
    "    # 2. Response time vs set-size\n",
    "    sub_rt_means = np.concatenate(\n",
    "        [data.groupby(['setsize', 'subject']).rt_s.mean()[s][:,None]\n",
    "         for s in setsizes], axis=1)\n",
    "    # 3. P(choose best seen item )\n",
    "    sub_best_seen_chosen_means = np.concatenate(\n",
    "        [data.groupby(['setsize','subject']).best_seen_chosen.mean()[s][:,None]\n",
    "         for s in setsizes], axis=1)\n",
    "    \n",
    "    # 4. P(last gaze to choice)\n",
    "    (sub_p_last_fix_choice_means,\n",
    "     p_last_fix_choice_means,\n",
    "     p_last_fix_choice_sems) = compute_p_last_gaze_choice(data, gaze_data)\n",
    "    \n",
    "    # 5. Gaze Influence on choice probability\n",
    "    sub_gaze_influence_scores = []\n",
    "    for setsize in setsizes:\n",
    "        sub_gaze_influence_scores.append(\n",
    "            compute_gaze_influence_score(data[data['setsize']==setsize].copy())[:,None])\n",
    "    sub_gaze_influence_scores = np.concatenate(sub_gaze_influence_scores, axis=1)\n",
    "    \n",
    "    # compute correlation matrix\n",
    "    corr_mat = compute_associations_figure_4F(data, gaze_data, setsizes=np.array([9,16,25,36]))\n",
    "    \n",
    "    # PLOT: \n",
    "    fig, axs = plt.subplots(4,4,figsize=cm2inch(20,20), dpi=dpi)\n",
    "        \n",
    "    axs[0,0].set_xlim(-0.05,1.05)\n",
    "    axs[0,0].set_ylim(-0.05,1.05)\n",
    "    axs[0,0].set_xlabel('P(best seen item chosen)', fontsize=fontsize)\n",
    "    axs[0,0].set_ylabel('% items seen', fontsize=fontsize)\n",
    "    _scatter(sub_best_seen_chosen_means.mean(axis=1), sub_frac_items_seen.mean(axis=1), \n",
    "             ax=axs[0,0], color='gray')\n",
    "    annotation = _annotation(1,0,corr_mat)\n",
    "    axs[0,0].set_title(annotation, fontsize=6)\n",
    "        \n",
    "    axs[1,0].set_xlim(-0.05,1.05)\n",
    "    axs[1,0].set_ylim(0,15)\n",
    "    axs[1,0].set_xlabel('P(best seen item chosen)', fontsize=fontsize)\n",
    "    axs[1,0].set_ylabel('Mean RT (s)', fontsize=fontsize)\n",
    "    _scatter(sub_best_seen_chosen_means.mean(axis=1), sub_rt_means.mean(axis=1),\n",
    "            ax=axs[1,0], color='gray')\n",
    "    annotation = _annotation(2,0,corr_mat)\n",
    "    axs[1,0].set_title(annotation, fontsize=6)\n",
    "        \n",
    "    axs[2,0].set_xlim(-0.05,1.05)\n",
    "    axs[2,0].set_ylim(-0.05,1.05)\n",
    "    axs[2,0].set_xlabel('P(best seen item chosen)', fontsize=fontsize)\n",
    "    axs[2,0].set_ylabel('P(last seen item chosen)', fontsize=fontsize)\n",
    "    _scatter(sub_best_seen_chosen_means.mean(axis=1), sub_p_last_fix_choice_means.mean(axis=1),\n",
    "            ax=axs[2,0], color='gray')\n",
    "    annotation = _annotation(3,0,corr_mat)\n",
    "    axs[2,0].set_title(annotation, fontsize=6)\n",
    "        \n",
    "    axs[3,0].set_xlim(-0.05,1.05)\n",
    "    axs[3,0].set_ylim(-0.05,1.05)\n",
    "    axs[3,0].set_xlabel('P(best seen item chosen)', fontsize=fontsize)\n",
    "    axs[3,0].set_ylabel('Gaze influence\\non P(choose item)', fontsize=fontsize)\n",
    "    _scatter(sub_best_seen_chosen_means.mean(axis=1), sub_gaze_influence_scores.mean(axis=1),\n",
    "            ax=axs[3,0], color='gray')\n",
    "    annotation = _annotation(4,0,corr_mat)\n",
    "    axs[3,0].set_title(annotation, fontsize=6) \n",
    "            \n",
    "    axs[1,1].set_xlim(-0.05,1.05)\n",
    "    axs[1,1].set_ylim(0,15)\n",
    "    axs[1,1].set_xlabel('% items seen', fontsize=fontsize)\n",
    "    axs[1,1].set_ylabel('Mean RT (s)', fontsize=fontsize)\n",
    "    _scatter(sub_frac_items_seen.mean(axis=1), sub_rt_means.mean(axis=1),\n",
    "             ax=axs[1,1], color='gray')\n",
    "    annotation = _annotation(2,1,corr_mat)\n",
    "    axs[1,1].set_title(annotation, fontsize=6)\n",
    "        \n",
    "    axs[2,1].set_xlim(-0.05,1.05)\n",
    "    axs[2,1].set_ylim(-0.05,1.05)\n",
    "    axs[2,1].set_xlabel('% items seen', fontsize=fontsize)\n",
    "    axs[2,1].set_ylabel('P(last seen item chosen)', fontsize=fontsize)\n",
    "    _scatter(sub_frac_items_seen.mean(axis=1), sub_p_last_fix_choice_means.mean(axis=1),\n",
    "             ax=axs[2,1], color='gray')\n",
    "    annotation = _annotation(3,1,corr_mat)\n",
    "    axs[2,1].set_title(annotation, fontsize=6)\n",
    "        \n",
    "    axs[3,1].set_xlim(-0.05,1.05)\n",
    "    axs[3,1].set_ylim(-0.05,1.05)\n",
    "    axs[3,1].set_xlabel('% items seen', fontsize=fontsize)\n",
    "    axs[3,1].set_ylabel('Gaze influence\\non P(choose item)', fontsize=fontsize)\n",
    "    _scatter(sub_frac_items_seen.mean(axis=1), sub_gaze_influence_scores.mean(axis=1),\n",
    "             ax=axs[3,1], color='gray')\n",
    "    annotation = _annotation(4,1,corr_mat)\n",
    "    axs[3,1].set_title(annotation, fontsize=6)\n",
    "        \n",
    "    axs[2,2].set_xlim(0,15)\n",
    "    axs[2,2].set_ylim(-0.05,1.05)\n",
    "    axs[2,2].set_xlabel('Mean RT (s)', fontsize=fontsize)\n",
    "    axs[2,2].set_ylabel('P(last seen item chosen)', fontsize=fontsize)\n",
    "    _scatter(sub_rt_means.mean(axis=1), sub_p_last_fix_choice_means.mean(axis=1),\n",
    "             ax=axs[2,2], color='gray')\n",
    "    annotation = _annotation(3,2,corr_mat)\n",
    "    axs[2,2].set_title(annotation, fontsize=6)\n",
    "        \n",
    "    axs[3,2].set_xlim(0, 15)\n",
    "    axs[3,2].set_ylim(-0.05,1.05)\n",
    "    axs[3,2].set_xlabel('Mean RT (s)', fontsize=fontsize)\n",
    "    axs[3,2].set_ylabel('Gaze influence\\non P(choose item)', fontsize=fontsize)\n",
    "    _scatter(sub_rt_means.mean(axis=1), sub_gaze_influence_scores.mean(axis=1),\n",
    "             ax=axs[3,2], color='gray')\n",
    "    annotation = _annotation(4,2,corr_mat)\n",
    "    axs[3,2].set_title(annotation, fontsize=6)\n",
    "        \n",
    "    axs[3,3].set_xlim(-0.05,1.05)\n",
    "    axs[3,3].set_ylim(-0.05,1.05)\n",
    "    axs[3,3].set_xlabel('P(last seen item chosen)', fontsize=fontsize)\n",
    "    axs[3,3].set_ylabel('Gaze influence\\non P(choose item)', fontsize=fontsize)\n",
    "    _scatter(sub_p_last_fix_choice_means.mean(axis=1), sub_gaze_influence_scores.mean(axis=1),\n",
    "             ax=axs[3,3], color='gray')\n",
    "    annotation = _annotation(4,3,corr_mat)\n",
    "    axs[3,3].set_title(annotation, fontsize=6) \n",
    "        \n",
    "    # despine\n",
    "    for label, ax in zip(list('A   BC  DEF GHIJ'), axs.ravel()):\n",
    "        ax.text(-0.25, 1.25, label, transform=ax.transAxes,\n",
    "            fontsize=10, fontweight='bold', va='top')\n",
    "        despine(ax=ax)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "        \n",
    "    # remove unused axes\n",
    "    axs[0,1].set_visible(False)\n",
    "    axs[0,2].set_visible(False)\n",
    "    axs[1,2].set_visible(False)\n",
    "    axs[0,3].set_visible(False)\n",
    "    axs[1,3].set_visible(False)\n",
    "    axs[2,3].set_visible(False)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(11)\n",
    "\n",
    "fig, _ = figure_4_figure_supplement_1(data, gaze_data)\n",
    "fig.savefig(figure_dir+'Figure-4-figure-supplement-1_choice-psychometrics-associations.pdf', dpi=300)\n",
    "fig.savefig(figure_dir+'Figure-4-figure-supplement-1_choice-psychometrics-associations.png', dpi=300)\n",
    "fig.savefig(figure_dir+'Figure-4-figure-supplement-1_choice-psychometrics-associations.jpg', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
